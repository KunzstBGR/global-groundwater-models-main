{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a89b96a",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460bb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - Add x and y in a metatable\n",
    "# - Create a list with all needed sites\n",
    "# - Add soil texture to lookup table and save as csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe181bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'D:/Data/KIMoDIs/global-groundwater-models-main'\n",
    "\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
    "MODEL_PATH = os.path.join(BASE_PATH, 'models')\n",
    "RESULT_PATH = os.path.join(BASE_PATH, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e211aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old static features from Alex\n",
    "static_df = pd.read_feather(os.path.join(DATA_PATH, 'static.feather'))\n",
    "\n",
    "# Newly extracted\n",
    "static_df_new = pq.read_table(os.path.join(DATA_PATH, \"well_extracted_staticfeatures_all.parquet\"))\n",
    "static_df_new = static_df_new.to_pandas()\n",
    "static_df_new = static_df_new[static_df_new['well_id'].isin(static_df['proj_id'])]\n",
    "static_df_new.rename(columns={'well_id':'proj_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560c426",
   "metadata": {},
   "source": [
    "## Feature selection static features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60beca14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proj_id',\n",
       " 'custom_twi',\n",
       " 'probav_probavlcclass',\n",
       " 'eumohp_dsd2',\n",
       " 'eumohp_dsd3',\n",
       " 'eumohp_dsd4',\n",
       " 'eumohp_dsd5',\n",
       " 'eumohp_dsd6',\n",
       " 'eumohp_lp2',\n",
       " 'eumohp_lp3',\n",
       " 'eumohp_lp4',\n",
       " 'eumohp_lp5',\n",
       " 'eumohp_lp6',\n",
       " 'eumohp_sd2',\n",
       " 'eumohp_sd3',\n",
       " 'eumohp_sd4',\n",
       " 'eumohp_sd5',\n",
       " 'eumohp_sd6',\n",
       " 'gwn_recharge',\n",
       " 'hyraum_gr',\n",
       " 'copernicus_lai01',\n",
       " 'copernicus_lai02',\n",
       " 'copernicus_lai03',\n",
       " 'copernicus_lai04',\n",
       " 'copernicus_lai05',\n",
       " 'copernicus_lai06',\n",
       " 'copernicus_lai07',\n",
       " 'copernicus_lai08',\n",
       " 'copernicus_lai09',\n",
       " 'copernicus_lai10',\n",
       " 'copernicus_lai11',\n",
       " 'copernicus_lai12',\n",
       " 'fk10dm1000_fc',\n",
       " 'amatulli_entgeom10kment',\n",
       " 'amatulli_shannongeom10kmsha',\n",
       " 'amatulli_unigeom10kmuni',\n",
       " 'huek250_ha',\n",
       " 'huek250_kf',\n",
       " 'boart1000_st']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata:\n",
    "# D:\\Data\\github\\anyextract\\data_proj\n",
    "# list(static_df_new)\n",
    "\n",
    "# eumohp, dsd, sd bis zur 6. Ordnung, \n",
    "# gwn_recharge, \n",
    "# hyraum_r, hyraum_gr, -> welchen?\n",
    "# permeability coefficient (kf) -> überspannende Kategorien\n",
    "# aquifer type (ha)\n",
    "# soil type -> sehr viele Kategorien (557), erstmal nicht verwendet (buek_250bt)\n",
    "# land_cover\n",
    "# elevation\n",
    "# topographischer Feuchteindex\n",
    "# bodenart\n",
    "# feldkapazität\n",
    "\n",
    "# Subset\n",
    "static_subset = static_df_new.filter(regex='proj_id|eumohp.+[0-6]|entgeom10kment|shannongeom10kmsha|unigeom10kmuni|gwn_recharge|hyraum_gr|huek250_kf|huek250_ha|probavlcclass|lai.*|twi|fk10dm1000_fc|boart1000_st')\n",
    "list(static_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc29981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunz.s\\AppData\\Local\\Temp\\16\\ipykernel_37048\\3346767697.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  static_subset.rename(columns=column_mapping, inplace=True)\n",
      "C:\\Users\\kunz.s\\AppData\\Local\\Temp\\16\\ipykernel_37048\\3346767697.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  static_subset.rename(columns={'probav_probavlcclass':'land_cover',\n"
     ]
    }
   ],
   "source": [
    "# MOHP is acutally 1-5\n",
    "# Define a mapping to change MOHP names \n",
    "column_mapping_dsd = {f'eumohp_dsd{i}': f'eumohp_dsd{i-1}' for i in range(2, 7)} \n",
    "column_mapping_lp = {f'eumohp_lp{i}': f'eumohp_lp{i-1}' for i in range(2, 7)}\n",
    "column_mapping_sd = {f'eumohp_sd{i}': f'eumohp_sd{i-1}' for i in range(2, 7)}\n",
    "column_mapping = {**column_mapping_dsd, **column_mapping_lp, **column_mapping_sd}\n",
    "column_mapping\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "static_subset.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Remaining columns with hard to understand column names\n",
    "static_subset.rename(columns={'probav_probavlcclass':'land_cover', \n",
    "                              'huek250_ha':'aquifer_type', \n",
    "                              'huek250_kf':'permeability_coef', \n",
    "                              'boart1000_st': 'soil_texture', \n",
    "                              'fk10dm1000_fc': 'field_capacity',\n",
    "                              'custom_twi': 'twi', \n",
    "                              'gwn_recharge': 'gw_recharge',\n",
    "                              'amatulli_entgeom10kment': 'landform_entr10km', \n",
    "                              'amatulli_shannongeom10kmsha': 'landform_sha10km', \n",
    "                              'amatulli_unigeom10kmuni': 'landform_uni10km'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854aad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b4b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rm where aquifer type, k.A. (kf == 0 does not exist)\n",
    "static_subset = static_subset[static_subset['aquifer_type']!='k.A.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6815b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kf überspannende Kategorien zusammenfassen\n",
    "# static_subset[static_subset['permeability_coef']==0]\n",
    "# 'hoch' didn't need to be aggregated with 'sehr hoch', because 'sehr hoch didn't exist\n",
    "static_subset.loc[static_subset['permeability_coef'].isin(['3','4']), 'permeability_coef'] = '9'\n",
    "static_subset.loc[static_subset['permeability_coef'].isin(['5','6','7']), 'permeability_coef'] = '10'\n",
    "\n",
    "# Mäßig bis gering occurs 897 times and is an in-between category\n",
    "# static_subset[static_subset['permeability_coef']=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dadea1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', 'K/Ka', 'K', 'K/P', 'G']\n",
       "Categories (6, object): ['G', 'K', 'k.A.', 'K/Ka', 'K/P', 'P']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_subset['aquifer_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67567bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Land cover & soil texture should be categories\n",
    "col_convert = ['land_cover', 'soil_texture']\n",
    "static_subset[col_convert] = static_subset[col_convert].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef93e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add elevation from original dataset\n",
    "static_subset = static_subset.merge(static_df[['proj_id', 'elevation']], on='proj_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NAs\n",
    "static_subset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d37a2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One site doesn't have gwn recharge values\n",
    "# RM for now\n",
    "# static_subset[static_subset['gwn_recharge'].isnull()]\n",
    "static_subset = static_subset[static_subset['gwn_recharge'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f261f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_missing = static_subset[static_subset['field_capacity'].isnull()][['proj_id', 'field_capacity']]\n",
    "fc_missing = pa.Table.from_pandas(fc_missing)\n",
    "pq.write_table(fc_missing, os.path.join(DATA_PATH, 'fc_missing.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "693aaecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31 sites with no eumohp values\n",
    "# RM for now\n",
    "# static_subset[static_subset['eumohp_dsd1'].isnull()]['proj_id'].unique())\n",
    "static_subset = static_subset[static_subset['eumohp_dsd1'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd31aa",
   "metadata": {},
   "source": [
    "## Temporal features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ee331",
   "metadata": {},
   "source": [
    "### Temperature, Humidity & Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abbad4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_df_new = pq.read_table(os.path.join(DATA_PATH, \"well_extracted_t_p_rh_1990-2020.parquet\"))\n",
    "temporal_df_new = temporal_df_new.to_pandas()\n",
    "temporal_df_new.rename(columns={'well_id': 'proj_id', \n",
    "                                'date': 'time',\n",
    "                                'p': 'precip',\n",
    "                                'hurs': 'humid', \n",
    "                                'tas': 'temp'}, inplace=True)\n",
    "temporal_df_new['time'] = pd.to_datetime(temporal_df_new['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a01af5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precip</th>\n",
       "      <th>humid</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.519660e+08</td>\n",
       "      <td>1.519660e+08</td>\n",
       "      <td>1.519660e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.909476e+00</td>\n",
       "      <td>7.760586e+01</td>\n",
       "      <td>9.925549e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.135705e+00</td>\n",
       "      <td>1.185131e+01</td>\n",
       "      <td>7.335859e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.654206e+01</td>\n",
       "      <td>-2.050000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.976090e+01</td>\n",
       "      <td>4.420087e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>7.913600e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.978661e+00</td>\n",
       "      <td>8.680000e+01</td>\n",
       "      <td>1.562035e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.630464e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>3.170000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precip         humid          temp\n",
       "count  1.519660e+08  1.519660e+08  1.519660e+08\n",
       "mean   1.909476e+00  7.760586e+01  9.925549e+00\n",
       "std    4.135705e+00  1.185131e+01  7.335859e+00\n",
       "min    0.000000e+00  1.654206e+01 -2.050000e+01\n",
       "25%    0.000000e+00  6.976090e+01  4.420087e+00\n",
       "50%    1.000000e-01  7.913600e+01  1.000000e+01\n",
       "75%    1.978661e+00  8.680000e+01  1.562035e+01\n",
       "max    2.630464e+02  1.000000e+02  3.170000e+01"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_df_new[['precip', 'humid', 'temp']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ab94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No NANs\n",
    "temporal_df_new.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe910adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data from 1990 until 2016\n",
    "temporal_df_new = temporal_df_new[(temporal_df_new['time']>='1990-01-01') & (temporal_df_new['time']<='2016-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "686d8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate from daily to weekly\n",
    "temporal_df_new.set_index('time', inplace = True)\n",
    "temporal_df_new = temporal_df_new.groupby('proj_id').resample('W')[['precip', 'humid', 'temp']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a99419",
   "metadata": {},
   "source": [
    "### Leaf Area Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26afcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the monthly values for each proj id:\n",
    "# - lai values are transformed to long format \n",
    "# - a month column is created to merge the lai values\n",
    "df_lai = static_df_new.filter(regex='proj_id|lai').melt(id_vars=['proj_id'], value_name='lai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4a6bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proj_id</th>\n",
       "      <th>variable</th>\n",
       "      <th>lai</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai01</td>\n",
       "      <td>0.341966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13475</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai02</td>\n",
       "      <td>0.201331</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26950</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai03</td>\n",
       "      <td>0.323954</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40425</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai04</td>\n",
       "      <td>0.580458</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53900</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai05</td>\n",
       "      <td>0.973662</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67375</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai06</td>\n",
       "      <td>1.164746</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80850</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai07</td>\n",
       "      <td>1.154863</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94325</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai08</td>\n",
       "      <td>0.946894</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107800</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai09</td>\n",
       "      <td>0.648462</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121275</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai10</td>\n",
       "      <td>0.365248</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134750</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai11</td>\n",
       "      <td>0.214833</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148225</th>\n",
       "      <td>HB_208</td>\n",
       "      <td>copernicus_lai12</td>\n",
       "      <td>0.252362</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       proj_id          variable       lai  month\n",
       "0       HB_208  copernicus_lai01  0.341966      1\n",
       "13475   HB_208  copernicus_lai02  0.201331      2\n",
       "26950   HB_208  copernicus_lai03  0.323954      3\n",
       "40425   HB_208  copernicus_lai04  0.580458      4\n",
       "53900   HB_208  copernicus_lai05  0.973662      5\n",
       "67375   HB_208  copernicus_lai06  1.164746      6\n",
       "80850   HB_208  copernicus_lai07  1.154863      7\n",
       "94325   HB_208  copernicus_lai08  0.946894      8\n",
       "107800  HB_208  copernicus_lai09  0.648462      9\n",
       "121275  HB_208  copernicus_lai10  0.365248     10\n",
       "134750  HB_208  copernicus_lai11  0.214833     11\n",
       "148225  HB_208  copernicus_lai12  0.252362     12"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the month number from the 'variable' column \n",
    "df_lai['month'] = df_lai['variable'].str.extract(r'(\\d+)').astype(int)\n",
    "# Example\n",
    "df_lai[df_lai['proj_id']=='HB_208']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bd6fa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proj_id     False\n",
       "variable    False\n",
       "lai         False\n",
       "month       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No nan's\n",
    "df_lai.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f28e2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_df_new['month'] = temporal_df_new['time'].dt.month\n",
    "temporal_df_new = temporal_df_new.merge(df_lai[['proj_id', 'month', 'lai']], \n",
    "                                        on=['proj_id', 'month'], \n",
    "                                        how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f83aef",
   "metadata": {},
   "source": [
    "### Day as circular variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65f31de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode day of the year as circular feature\n",
    "temporal_df_new['day_sin'] = np.sin(2*np.pi / 365. * temporal_df_new['time'].dt.dayofyear).astype(np.float32)\n",
    "temporal_df_new['day_cos'] = np.cos(2*np.pi / 365. * temporal_df_new['time'].dt.dayofyear).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8bf67",
   "metadata": {},
   "source": [
    "## Merge spatial and temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d534db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_df_new.drop(['month'], axis=1, inplace=True)\n",
    "# Some sites in temproal_df that are not in the static_features\n",
    "temporal_df_new = temporal_df_new[temporal_df_new['proj_id'].isin(static_subset['proj_id'])]\n",
    "features_df = temporal_df_new.merge(static_subset, on='proj_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d41656d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rm lai columns\n",
    "col_lai = list(features_df.filter(regex = 'copernicus.*'))\n",
    "features_df.drop(col_lai, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f648f5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proj_id',\n",
       " 'time',\n",
       " 'precip',\n",
       " 'humid',\n",
       " 'temp',\n",
       " 'lai',\n",
       " 'day_sin',\n",
       " 'day_cos',\n",
       " 'twi',\n",
       " 'land_cover',\n",
       " 'eumohp_dsd1',\n",
       " 'eumohp_dsd2',\n",
       " 'eumohp_dsd3',\n",
       " 'eumohp_dsd4',\n",
       " 'eumohp_dsd5',\n",
       " 'eumohp_lp1',\n",
       " 'eumohp_lp2',\n",
       " 'eumohp_lp3',\n",
       " 'eumohp_lp4',\n",
       " 'eumohp_lp5',\n",
       " 'eumohp_sd1',\n",
       " 'eumohp_sd2',\n",
       " 'eumohp_sd3',\n",
       " 'eumohp_sd4',\n",
       " 'eumohp_sd5',\n",
       " 'gwn_recharge',\n",
       " 'hyraum_gr',\n",
       " 'landform_entr10km',\n",
       " 'landform_sha10km',\n",
       " 'landform_uni10km',\n",
       " 'aquifer_type',\n",
       " 'permeability_coef',\n",
       " 'soil_texture',\n",
       " 'elevation']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6b07285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proj_id              False\n",
       "time                 False\n",
       "precip               False\n",
       "humid                False\n",
       "temp                 False\n",
       "lai                  False\n",
       "day_sin              False\n",
       "day_cos              False\n",
       "twi                  False\n",
       "land_cover           False\n",
       "eumohp_dsd1          False\n",
       "eumohp_dsd2          False\n",
       "eumohp_dsd3          False\n",
       "eumohp_dsd4          False\n",
       "eumohp_dsd5          False\n",
       "eumohp_lp1           False\n",
       "eumohp_lp2           False\n",
       "eumohp_lp3           False\n",
       "eumohp_lp4           False\n",
       "eumohp_lp5           False\n",
       "eumohp_sd1           False\n",
       "eumohp_sd2           False\n",
       "eumohp_sd3           False\n",
       "eumohp_sd4           False\n",
       "eumohp_sd5           False\n",
       "gwn_recharge         False\n",
       "hyraum_gr            False\n",
       "landform_entr10km    False\n",
       "landform_sha10km     False\n",
       "landform_uni10km     False\n",
       "aquifer_type         False\n",
       "permeability_coef    False\n",
       "soil_texture         False\n",
       "elevation            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd8e2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "cols = ['proj_id',\n",
    "     'time',\n",
    "     'precip',\n",
    "     'humid',\n",
    "     'temp',\n",
    "     'lai',\n",
    "     'day_sin',\n",
    "     'day_cos',\n",
    "     'twi',\n",
    "     'gw_recharge',\n",
    "     'hyraum_gr',\n",
    "     'aquifer_type',\n",
    "     'permeability_coef',\n",
    "     'soil_texture',\n",
    "     'elevation',\n",
    "     'land_cover',\n",
    "     'landform_entr10km',\n",
    "     'landform_sha10km',\n",
    "     'landform_uni10km',\n",
    "     'eumohp_dsd1',\n",
    "     'eumohp_dsd2',\n",
    "     'eumohp_dsd3',\n",
    "     'eumohp_dsd4',\n",
    "     'eumohp_dsd5',\n",
    "     'eumohp_lp1',\n",
    "     'eumohp_lp2',\n",
    "     'eumohp_lp3',\n",
    "     'eumohp_lp4',\n",
    "     'eumohp_lp5',\n",
    "     'eumohp_sd1',\n",
    "     'eumohp_sd2',\n",
    "     'eumohp_sd3',\n",
    "     'eumohp_sd4',\n",
    "     'eumohp_sd5']\n",
    "features_df = features_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c6d4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as parquet\n",
    "table_features = pa.Table.from_pandas(features_df)\n",
    "pq.write_table(table_features, os.path.join(DATA_PATH, 'features_df.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842254d0",
   "metadata": {},
   "source": [
    "## Lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48469062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permeability coefficient (kf in m/s)\n",
    "kf_lc = {'kf':[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 99], \n",
    "         'meaning': ['keine Angaben', \n",
    "                     'sehr hoch (>1E-2)',\n",
    "                     'hoch >(1E-3 - 1E-2)',\n",
    "                     'mittel (>1E-4 - 1E-3)',\n",
    "                     'mäßig (1E-5 - 1E-4)',\n",
    "                     'gering (>1E-7 - 1E-5)', \n",
    "                     'sehr gering (>1E-9 - 1E-7)', \n",
    "                     'äußerst gering (<1E-9)', \n",
    "                     'sehr hoch bis hoch (>1E-3)', \n",
    "                     'mittel bis mäßig (>1E-5 - 1E-3)', \n",
    "                     'gering bis äußerst gering (<1E-5)', \n",
    "                     'stark variabel', \n",
    "                     'mäßig bis gering (>1E-6 - 1E-4)', \n",
    "                     'Gewässer']}\n",
    "kf_lc = pd.DataFrame(data=kf_lc)\n",
    "\n",
    "# Aquifer type\n",
    "aquifertype_lc = {'code':[None, 1, 2, 3, 4, 5], \n",
    "                  'abbrev':['k.A', 'P', 'K/P', 'K', 'K/KA', 'G'] ,\n",
    "                  'aq_type':['keine Angaben', 'Poren', 'Kluft/Poren', 'Kluft', 'Kluft/Karst', 'Gewässer']}\n",
    "aquifertype_lc = pd.DataFrame(data = aquifertype_lc)\n",
    "\n",
    "# Hyraum\n",
    "hyraum_lc = {'code':[1, 11, 12, 13, 14, 15, 16, 17, \n",
    "                     2, 21, 22, 23,\n",
    "                     3, 31, 32, 33, \n",
    "                     4, 41,\n",
    "                     5, 51, 52, 53, 54, \n",
    "                     6, 61, 62, 63, 64, 65, 66,\n",
    "                     7, 71, \n",
    "                     8, 81, 82, 83, \n",
    "                     9, 91, 92, 93, 94, 95, 96, 97,\n",
    "                     10, 101], \n",
    "             'hyraum':['Nord- und mitteldt. Lockergesteinsgebiet', 'Nordseeinseln und Watten', 'Nordseemarschen', 'Niederungen im nord-und mitteldt. Lockergesteinsgebiet', 'Norddeutsches Jungpleistozän', 'Nord- und mitteldt. Mittelpleistozän', 'Altmoränengeest', 'Lausistzer Känozoikum',\n",
    "                       'Rheinisch-Westfälisches Tiefland', 'Sandmünsterland', 'Münsterländer Kreidebecken', 'Niederrheinische Tieflandsbucht', \n",
    "                       'Oberrheingraben mit Mainzer Becken und nordhessischem Tertiär', 'Oberrheingraben mit Mainzer Becken', 'Untermainsenke', 'Nordhessisches Tertiär', \n",
    "                       'Alpenvorland', 'Süddeutsches Molassebecken', \n",
    "                       'Mitteldeutsches Bruchschollenland', 'Nordwestdeutsches Bergland', 'Mitteldeutscher Buntsandstein', 'Subherzyne Senke', 'Thüringische Senke', \n",
    "                       'West- und süddeutsches Schichtstufen- und Bruchschollenland', 'Südwestdeutsche Trias', 'Süddeutscher Buntsandstein und Muschelkalk', 'Süddeutscher Keuper und Albvorland', 'Schwäbische und Fränkische Alb', 'Nördlinger Ries', ' Thüringisch-Fränkisches Bruchschollenland',\n",
    "                       'Alpen', 'Nordalpen', \n",
    "                       'West- und mitteldeutsches Grundgebirge', ' Rheinisches Schiefergebirge', ' Saar-Nahe-Becken', 'Mitteldeutsches Grundgebirge', \n",
    "                       'Südostdeutsches Grundgebirge', 'Elbtalgraben', 'Fichtelgebirge-Erzgebirge', 'Lausitzer Granodioritkomplex', 'Nordwestsächsische Senke', 'Oberpfälzer-Bayrischer Wald', 'Südostdeutsches Schiefergebirge', 'Thüringer Wald', \n",
    "                       'Südwestdeutsches Grundgebirge', 'Schwarzwald, Vorspeesart und Odenwald']}\n",
    "hyraum_lc = pd.DataFrame(data = hyraum_lc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
